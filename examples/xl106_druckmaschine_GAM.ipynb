{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import sys\n",
    "sys.path.append('/Users/wastechs/Documents/git-repos/energy-efficiency')\n",
    "from lib.util.helper import query_table, weekday_time_series\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
    "import plotly\n",
    "from prophet.plot import plot_plotly, plot_components_plotly\n",
    "from prophet.plot import add_changepoints_to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "druck = weekday_time_series(sensor_id='xl106_druckmaschine_5T')\n",
    "druck['kw'] = round(druck['kw'], 2)\n",
    "druck['kw'] = druck['kw'].apply(lambda x: 0.0 if x == -0.0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plotly.offline.init_notebook_mode()\n",
    "px.line(\n",
    "    x=druck.index, y=druck.kw, \n",
    "    title='Xl106 Druckmaschine - Sampled at 5 minute intervals',\n",
    "    labels={\n",
    "        'x': 'Time',\n",
    "        'y': 'kW'\n",
    "    },\n",
    "    markers=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Generalized Additive Model with Facebook's Prophet\n",
    "\n",
    "\"A fancy name for the **summation** of the outputs of different models\"\n",
    "\n",
    "$y(t) = g(t) + s(t) + h(t) + \\epsilon_t$\n",
    "\n",
    "where\n",
    "\n",
    "$y(t) = $ output at time $t$\n",
    "\n",
    "$g(t) = $ models non-periodic changes (growth)\n",
    "\n",
    "$s(t) = $ models periodic changes using Fourier basis functions\n",
    "\n",
    "$h(t) = $ holidays or other special \"events\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Piecewise Linear Model $g(t)$\n",
    "\n",
    "Since the machine time series does not exhibit an increasing or decreasing growth / trend, a piecewise constant rate of growth is suitable:\n",
    "\n",
    " $g(t) = (k + a(t)^T\\delta)t + (m + a(t)^T\\gamma)$\n",
    "\n",
    " where\n",
    "\n",
    "\n",
    "$k = $ growth rate\n",
    "\n",
    "$\\delta = $ rate adjustments\n",
    "\n",
    "$m = $ offset parameter\n",
    "\n",
    "$\\gamma_j = $ is set to $-s_j\\delta_j$ to make the function continuous\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Diving into $g(t)$\n",
    "\n",
    "$g(t) = (k + a(t)^T\\delta)t$\n",
    "\n",
    "The growth model consists of a base trend $k$ and preset changepoints at which the growth rate can be adjusted by $s_j$\n",
    " - These preset changepoints are defined in an $S$ vector with changepoints at times $s_j = 1, . . .,S$\n",
    "\n",
    "At each unique changepoint $s_j$, the growth rate is **adjusted** by $\\delta_j$\n",
    " - Thus, we can define all growth rate adjustments by the vector $\\delta$\n",
    "\n",
    "Summary - The growth rate is adjusted every time step that $t$ surpasses a changepoint $s_j$. The growth rate then becomes the base rate plus the sum of all adjustments up to that point:\n",
    "\n",
    "$k + \\sum_{j:t > s_j}\\delta_j$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Specifying Changepoints and Their Scale\n",
    "\n",
    "The changepoints $s_j$ can be specified by the analyst using known dates / times of machine operation, product launches and other growth / trend altering events\n",
    " - Or, it may be automatically selected given a set of candidates (namely, by specifying a distribution)\n",
    "\n",
    "If we want to specify a large number of changepoints, i.e., machine start up, shut down, standy by, etc. then we can specify a prior distribution on $\\delta$:\n",
    "\n",
    "$\\delta$ ~ $Laplace(0, \\tau)$\n",
    "\n",
    "where\n",
    "\n",
    "$\\tau = $ directly controls the flexibility of the model in altering its rate (higher $\\tau$ values make the model follow the variance better, but increase overfitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Seasonality With Fourier Basis Functions\n",
    "\n",
    "A Fourier sum can approximate **any** arbitrary periodic signal:\n",
    "\n",
    "$s(t) = \\sum^N_{n=1} \\left[a_n \\text{cos}\\left(\\frac{2 \\pi nt}{P} \\right) + b_n \\text{sin}\\left(\\frac{2 \\pi nt}{P}\\right) \\right]$\n",
    "\n",
    "The number of terms in the partial sum (the order parameter in Prophet) determines how quickly the seasonality can change and the period $P$ is the length of the cycle, i.e., 365.25 for yearly data or 7 for weekly data)\n",
    " - Higher order values indicate higher frequency changes\n",
    "\n",
    "Fourier Basis functions are a collection of $sine$ and $cosine$ functions that can be used for approximating arbitrary smooth seasonal effects \n",
    " - _The Idea_: We can capture the sesonal effects of the machines (hour of day, weekly, . . .) with the fourier basis functinos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summarizing\n",
    "\n",
    "The output $y$ at time $t$ is a function of:\n",
    "\n",
    "$g(t)$ = which is the growth at time $t$ which itself is conditional on whether $t$ is $>$ a changepoint $s_j$ and the degree of the effect of the changepoint is determined by $\\delta$ which can be specified a priori\n",
    "\n",
    "$s(t)$ = which is pre-defined seasonality components based on domain knowledge, i.e., hourly and weekly seasonality of electricity consumption typically conditional on production schedules and human behavior\n",
    "\n",
    "$h(t) = $ Swiss holidays or Gassmann special days (yet to be defined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Positive skew in the variance of the time series could be a problem as GAMs assume Gaussian noise of the residuals\n",
    " - How to handle when the machine is off? (0 values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = pd.Timestamp('2021-10-11')\n",
    "end_time = pd.Timestamp('2021-10-15')\n",
    "druck[(druck.index.date >= time) & (druck.index.date <= end_time)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "train_druck = druck[druck.index.day <= 14]\n",
    "test_druck = druck[druck.index.day >= 15]\n",
    "train_druck.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "test_druck.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "train_druck = pd.DataFrame(data=train_druck['kw'], index=train_druck.index)\n",
    "test_druck = pd.DataFrame(data=test_druck['kw'], index=test_druck.index)\n",
    "\n",
    "train_druck.reset_index(inplace=True)\n",
    "test_druck.reset_index(inplace=True)\n",
    "\n",
    "# Standardizing helps with convergence\n",
    "scale = StandardScaler()\n",
    "\n",
    "train_druck['kw'] = scale.fit_transform(train_druck['kw'].values.reshape(-1, 1))\n",
    "\n",
    "scale.fit(train_druck['kw'].values.reshape(-1, 1))\n",
    "test_druck['kw'] =  scale.transform(test_druck['kw'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Prophet Naming Conventions\n",
    "train_druck = train_druck.rename(columns={'t': 'ds', 'kw': 'y'})\n",
    "test_druck = test_druck.rename(columns={'t': 'ds', 'kw': 'y'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.infer_freq(train_druck.ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_druck['ds'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Training dataframe is ready\n",
    "train_druck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_prior = np.arange(0.05, 20, 0.05)\n",
    "tau_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def build_prophet_model(df, future, changepoint_prior_scale=0.05, other_seasonality=None):\n",
    "    \n",
    "    # Initializing the model\n",
    "    m = Prophet(\n",
    "        changepoint_prior_scale=changepoint_prior_scale,\n",
    "        growth='linear'\n",
    "        #seasonality_mode='multiplicative'\n",
    "    )\n",
    "    \n",
    "    # Add additional seasonality such as \"hourly\" seasonality\n",
    "    # Higher fourier order captures how \"quickly\" the seasonality can change\n",
    "    m.add_seasonality(name='hourly', period=0.041, fourier_order=30)\n",
    "\n",
    "    m.fit(df)\n",
    "    forecast = m.predict(future)\n",
    "\n",
    "    return m, forecast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# For forecasting - build a dataframe with frequency and length of time to forecast\n",
    "future = pd.DataFrame(\n",
    "    data=pd.date_range('2021-10-11 00:00:00', '2021-10-15 23:55:00', freq='5T'),\n",
    "    columns=['ds']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial log joint probability = -153.606\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1261.54     0.0600397        30.983           1           1      122   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       1268.94       0.14614       27.7546           1           1      237   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1275.04     0.0128378       21.3134           1           1      351   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399        1276.8    0.00273899       18.9906      0.8598      0.8598      469   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     499       1282.37      0.011732       35.9639           1           1      583   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       1284.12     0.0332167       11.3837           1           1      698   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     604       1284.16    0.00012339       6.21238   1.628e-05       0.001      738  LS failed, Hessian reset \n",
      "     673       1284.62   0.000843613       17.6265   0.0001075       0.001      855  LS failed, Hessian reset \n",
      "     699       1285.06    0.00381346       6.61954      0.3245      0.3245      887   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     799       1285.61     0.0218183       16.8123           1           1     1016   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     805       1285.63   0.000567488       9.78849   7.505e-05       0.001     1063  LS failed, Hessian reset \n",
      "     899        1285.9    0.00143262       8.40754      0.5374      0.5374     1185   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     999       1286.66    0.00488571       21.3214           1           1     1301   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1099       1287.99      0.029167       32.5495           1           1     1423   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1132       1288.21   0.000194324       9.38894   1.299e-05       0.001     1497  LS failed, Hessian reset \n",
      "    1167        1288.3   0.000218899       8.32208   4.296e-05       0.001     1572  LS failed, Hessian reset \n",
      "    1199       1288.33   0.000306898       2.10978           1           1     1614   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1234       1288.37   0.000103706       5.67987   1.526e-05       0.001     1705  LS failed, Hessian reset \n",
      "    1256       1288.39   7.58727e-05         4.017   1.309e-05       0.001     1765  LS failed, Hessian reset \n",
      "    1269       1288.39   6.19039e-05       4.64524   1.599e-05       0.001     1828  LS failed, Hessian reset \n",
      "    1299       1288.42     0.0205184       19.4754           1           1     1868   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1363       1288.54   0.000347145       7.22535   0.0001466       0.001     1988  LS failed, Hessian reset \n",
      "    1377       1288.55   9.26533e-05       5.20484   2.454e-05       0.001     2042  LS failed, Hessian reset \n",
      "    1399       1288.55   2.55307e-05       3.77011           1           1     2079   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1497       1288.57   1.06699e-05       3.02442   3.616e-06       0.001     2246  LS failed, Hessian reset \n",
      "    1499       1288.57   7.85674e-06        3.7647           1           1     2248   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "    1504       1288.57   4.04104e-08       3.76644    0.009675    0.009675     2257   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n"
     ]
    }
   ],
   "source": [
    "# Running the model\n",
    "model, predictions = build_prophet_model(train_druck, future, 0.8, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1440"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = pd.concat([train_druck, test_druck])\n",
    "len(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "full_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Predictions\n",
    "\n",
    "_For observation #500_\n",
    "\n",
    "$\\hat{y} = g(t) + s(t)$ = **0.763812**\n",
    "\n",
    "$g(2021-10-12 \\space 17:40:00) = 0.556047$\n",
    "\n",
    "$s(2021-10-12 \\space 17:40:00) = 0.207765$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5n/lzw120x534d6n5nbhk8qwzjr0000gs/T/ipykernel_12420/3656225224.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Clamp predictions below 0 kw to 0\n",
    "#predictions['yhat'] = predictions['yhat'].apply(lambda x: -1.0 if x <= 0 else x)\n",
    "coef = predictions[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]\n",
    "coef['actual'] = full_df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>yhat</th>\n",
       "      <th>yhat_lower</th>\n",
       "      <th>yhat_upper</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-11 00:00:00</td>\n",
       "      <td>-1.064864</td>\n",
       "      <td>-1.731025</td>\n",
       "      <td>-0.401589</td>\n",
       "      <td>-1.003311e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-11 00:05:00</td>\n",
       "      <td>-1.119374</td>\n",
       "      <td>-1.808972</td>\n",
       "      <td>-0.502411</td>\n",
       "      <td>-1.003311e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-10-11 00:10:00</td>\n",
       "      <td>-1.115581</td>\n",
       "      <td>-1.774817</td>\n",
       "      <td>-0.507992</td>\n",
       "      <td>-1.003311e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-10-11 00:15:00</td>\n",
       "      <td>-1.130289</td>\n",
       "      <td>-1.848114</td>\n",
       "      <td>-0.440091</td>\n",
       "      <td>-1.003311e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-10-11 00:20:00</td>\n",
       "      <td>-1.034134</td>\n",
       "      <td>-1.695917</td>\n",
       "      <td>-0.376528</td>\n",
       "      <td>-1.003311e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>2021-10-15 23:35:00</td>\n",
       "      <td>-0.507794</td>\n",
       "      <td>-3.951225</td>\n",
       "      <td>3.117613</td>\n",
       "      <td>2.467162e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>2021-10-15 23:40:00</td>\n",
       "      <td>-0.565426</td>\n",
       "      <td>-4.042371</td>\n",
       "      <td>3.069882</td>\n",
       "      <td>2.467162e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>2021-10-15 23:45:00</td>\n",
       "      <td>-0.548686</td>\n",
       "      <td>-3.879978</td>\n",
       "      <td>3.092577</td>\n",
       "      <td>2.467162e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>2021-10-15 23:50:00</td>\n",
       "      <td>-0.542532</td>\n",
       "      <td>-4.061129</td>\n",
       "      <td>3.050827</td>\n",
       "      <td>2.467162e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>2021-10-15 23:55:00</td>\n",
       "      <td>-0.605800</td>\n",
       "      <td>-4.007110</td>\n",
       "      <td>3.199009</td>\n",
       "      <td>2.467162e-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ds      yhat  yhat_lower  yhat_upper        actual\n",
       "0    2021-10-11 00:00:00 -1.064864   -1.731025   -0.401589 -1.003311e+00\n",
       "1    2021-10-11 00:05:00 -1.119374   -1.808972   -0.502411 -1.003311e+00\n",
       "2    2021-10-11 00:10:00 -1.115581   -1.774817   -0.507992 -1.003311e+00\n",
       "3    2021-10-11 00:15:00 -1.130289   -1.848114   -0.440091 -1.003311e+00\n",
       "4    2021-10-11 00:20:00 -1.034134   -1.695917   -0.376528 -1.003311e+00\n",
       "...                  ...       ...         ...         ...           ...\n",
       "1435 2021-10-15 23:35:00 -0.507794   -3.951225    3.117613  2.467162e-17\n",
       "1436 2021-10-15 23:40:00 -0.565426   -4.042371    3.069882  2.467162e-17\n",
       "1437 2021-10-15 23:45:00 -0.548686   -3.879978    3.092577  2.467162e-17\n",
       "1438 2021-10-15 23:50:00 -0.542532   -4.061129    3.050827  2.467162e-17\n",
       "1439 2021-10-15 23:55:00 -0.605800   -4.007110    3.199009  2.467162e-17\n",
       "\n",
       "[1440 rows x 5 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.56895107635984, 1876984565988823.2)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_all = coef[coef['ds'] >= '2021-10-15']\n",
    "truth = test_all['actual']\n",
    "preds = test_all['yhat']\n",
    "\n",
    "rmse = mean_squared_error(truth, preds)\n",
    "mape = mean_absolute_percentage_error(truth, preds)\n",
    "rmse, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1850670436279975"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mape = mean_absolute_percentage_error(coef['actual'], coef['yhat'])\n",
    "rmse = mean_squared_error(coef['actual'], coef['yhat'])\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Get actual values outside of 95% CI\n",
    "oob_upper = np.array(np.where(coef['actual'] > coef['yhat_upper'])).flatten()\n",
    "oob_lower = np.array(np.where(coef['actual'] < coef['yhat_lower'])).flatten()\n",
    "\n",
    "oob_upper = coef.iloc[oob_upper]\n",
    "oob_lower = coef.iloc[oob_lower]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Forecasted values seasonal components\n",
    "model.plot_components(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "upper = oob_upper['actual'].to_numpy()\n",
    "lower = oob_lower['actual'].to_numpy()\n",
    "upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig = plot_plotly(model, predictions, uncertainty=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "fig = model.plot(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# We can also plot the changepoints\n",
    "a = add_changepoints_to_plot(fig.gca(), model, predictions)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Deploying Models with Prophet\n",
    "\n",
    "Flow:\n",
    "\n",
    "1.) Train a \"good\" first model :)\n",
    "\n",
    "2.) Save model to json\n",
    "   - _Note: The json file will be portable across systems, and deserialization is backwards compatible with older versions of prophet._\n",
    "\n",
    "3.) As new data comes \"in\", pass the parameters from the saved model into the fitting for the next with the `kwarg` `init`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Saving fitted models\n",
    "import json\n",
    "from prophet.serialize import model_to_json, model_from_json\n",
    "\n",
    "with open('serialized_model.json', 'w') as fout:\n",
    "    json.dump(model_to_json(m), fout)  # Save fitted model\n",
    "\n",
    "with open('serialized_model.json', 'r') as fin:\n",
    "    m = model_from_json(json.load(fin))  # Load fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Updating fitted models as new data comes in\n",
    "def stan_init(m):\n",
    "    \"\"\"Retrieve parameters from a trained model.\n",
    "    \n",
    "    Retrieve parameters from a trained model in the format\n",
    "    used to initialize a new Stan model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    m: A trained model of the Prophet class.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A Dictionary containing retrieved parameters of m.\n",
    "    \n",
    "    \"\"\"\n",
    "    res = {}\n",
    "    for pname in ['k', 'm', 'sigma_obs']:\n",
    "        res[pname] = m.params[pname][0][0]\n",
    "    for pname in ['delta', 'beta']:\n",
    "        res[pname] = m.params[pname][0]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df = '<all the new data here in Prophet format>'\n",
    "train_df = '<subset df into train and test>'\n",
    "model = Prophet().fit(df)\n",
    "\n",
    "updated_model = Prophet().fit(train_df, init=stan_init(model))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "interpreter": {
   "hash": "55f578ea790fce859303417df5f33993e9db329ffe5a387d7c54812db965934b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
