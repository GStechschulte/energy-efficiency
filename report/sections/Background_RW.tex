\subsection{Overview of Energy Efficiency Estimation Methods}

Monitoring and or estimating the EE of buildings or industrial equipment often follows the same framework \cite{kini_methodology_2011}: (1) collection of metered data, (2) a baseline / benchmark model and reporting period is defined, and (3) continuous monitoring and comparison of baseline consumption to actual consumption. 

In (2), the reporting period is defined as the EE \textit{as is} and provides a baseline from which to measure, analyze, test and improve \cite{oakland_statistical_2008}. The baseline model, trained on the reporting period, can be defined as the energy characterization of the starting situation, and its role is fundamental in the assessment of EE and other \ac{KPIs}. Often, a baseline model in the form of a regression model, and more recently, additional methods such as \ac{NNs} or \ac{SVM} have been used. However, the studies below show that  \ac{MLR} seems to still be the choice of model used in industry, and in particular, when additional independent variables are correlated with the EE. Lastly, (3) is discussed below in \hyperlink{subsection.2.4}{Section 2.4}.

\subsection{Estimating and Monitoring Energy Efficiency in Industry}

In the literature, there is a vast amount of research and applications on electrical load forecasting. However, given our definition of EE and goal of developing an energy baseline model, the focus in this thesis is on operationalizing the predictions to monitor EE. In industry, this is often the difference between actual energy consumption versus the baseline model predictions. Namely, at predefined time points in the future, $x_{t+n}$, the equipment's input is predicted using the baseline model and is then compared to the actual result when the process is measured at that time step $x_{t+n}$ \cite{tightening}. 

Trager et.al \cite{tightening} used SPC, a technique often used in manufacturing in order to determine whether a process is changing based upon recent measurements. Using six months of data gathered from two commercial buildings in different locations, a \ac{STL} regression model was developed to predict one hour ahead for each time step. The entire prediction is then moved ahead one hour, so that at each time step in the procedure, one hour of data is predicted. The six months of training data acts as the baseline reporting period in which future predicted energy consumption is analyzed against. Then, using the residuals—the difference between the predictions and actual values—the authors use control charts to monitor EE and analyze deviations in building consumption which is talked about more in \hyperlink{subsection.2.5}{Section 2.5}. 


Benedetti et al. \cite{cas} in a case study with a pharmaceutical manufacturing plant demonstrated the importance of monitoring and controlling energy performance in \ac{CAS} using novel methodology based on meter data and a energy baseline definition using MLR and control charts (see \hyperlink{subsection.2.5}{Section 2.5}). To model the baseline energy performance of the system, a baseline reporting period of one year at $15$ minute intervals taking into account other independent variables such as compressed air production, external temperature, external humidity and pressure is chosen which displays the \textit{best} operating performance of the CAS. Then, using this reporting period, a regression model is developed which acts as the energy baseline model. In order to monitor the energy performance, the authors evaluate the residual between actual energy consumption and the prediction of the baseline model. 

Granderson et al. \cite{lawrence-lab} used two months of electrical load data (August-September) from a small office building complemented with outdoor air temperature to train an energy baseline-modeling agent. Then, the model was used to predict the load for the next two months (October—November). For the first three weeks, the \ac{RMSE} of the hourly load is $1.6$ \ac{kW}. Then, in the subsequent weeks, the RMSE doubled to $3.2$ kW. Investigation into this new behavior showed that the building had switched into a ``heating mode" at the end of October. The building manager had stated this should not happen due to the warmer weather, and as a result, a new \ac{HVAC} control change was implemented to deter these type of events from happening. 

Nikula et al.\cite{boiler} compared actual boiler efficiency in power stations with its expected efficiency which is an estimate of the highest historical efficiency in the corresponding process state using an identification period based on MLR. The process state is a particular state which is defined as a function of the variables selected using \ac{MI}. Two industrial boilers were analyzed with a capacity of $300$ $\text{MW}_{th}$ and $160$ $\text{MW}_{elec}$, and $220$ $\text{MW}_{th}$, respectively. Each boiler's time series was sampled at an interval of $1$hr. Boiler one included $143$ variables, trained on $810$ hours of data, and was tested (monitored) using $70$ hours. Boiler two included $125$ variables, trained on $72.5$ hours, monitored using $3.5$ hours. Using MI, the top two features were chosen and were discretized. The step size in the discretized feature represents a process state. Therefore, in the MLR model, the dependent variable represents the expected efficiency and the features step sizes define the process states. The difference between the actual and expected efficiency was monitored using control controls which is talked about in \hyperlink{subsection.2.5}{Section 2.5} and the two features chosen using MI were analyzed as a potential root cause of deviations.

Benedetto et al \cite{data-driven-MV}, in another application, using metered data from three commercial buildings, complemented with outdoor weather data and binary indicators of holidays, developed an energy baseline model to compare the energy consumption before and after an \ac{EEM}. Daily load profiles were first identified through the means of a \ac{GMM}. Then, a \ac{GAM}, using the load profiles of the previous seven days, outdoor temperature, sun altitude, wind speed, and a holiday flagging variable is used to model the electricity consumption. This baseline model is then used to compute the counterfactual energy consumption, i.e., the predicted energy consumption if no EEM had taken place. Using the proposed methodologies, upon the EEM in the commercial building, the model achieved an RMSE of $13\%$, $9.1\%$, and $7.8\%$, and predicted a decrease in consumption \ac{kWh} of $8.6\%$, $10.9\%$, $8.3\%$ for building $1$, $2$, and $3$, respectively.

\subsection{Overview of Performance Deviation Detection Methods}

In the previous section, \cite{tightening}\cite{cas}\cite{boiler}, had used a form of charting, built off of the baseline model, to identify when a machine or building was deviating from benchmark efficiency. In industry, this charting is often called SPC, or \ac{QC}, and monitors the residuals from the baseline model to measure the statistical significance of the actual energy use deviating from the predicted energy use. Thus, using SPC charts, operators and or production managers of the equipment can gain insight into EE over time and near real-time current deviations in performance \cite{oakland_statistical_2008}.

However, as the field of PDD is vast, it must be acknowledged that analyzing the residuals from regression models is not the only way to perform PDD. Rather, it is a natural extension of time series regression models. Other techniques, primarily using classification and clustering methods, have been proposed and used to perform PDD which will be briefly described here.

Zhang et al. \cite{gas-turbine-faults} used GMM techniques to provide recognition of operational states, extraction of load profiles, and to detect emerging faults for industrial turbines. To detect emerging faults, a normal operation state was recognized using a Bayesian GMM technique. Then, with this normal operation cluster a GMM was used to define an ellipse boundary to the cluster and when a new data point fell outside of the ellipse boundary it was identified as a fault. This method, which is now in production, allows the production managers and engineers to analyze, in real time, the performance of their equipment. Gallagher et al. \cite{intelliMAV} implemented a clustering based PDD in the framework of \ac{MV} to maintain energy savings. Du et al. \cite{fault-HVAC} combined NNs to detect abnormalities in the energy consumption of the HVAC system and used subtractive clustering to classify the abnormalities for diagnostic purposes.

\subsection{Performance Deviation Detection Methods in Industry}

As the main motivation in this thesis is centered around the idea of an energy baseline model, below, PDD based on the use of SPC charts is demonstrated.

Using the residuals from the STL model in \cite{tightening}, three control charts—a \ac{MA}, \ac{RO}, and a dual measure control chart combining the metrics of the MA and RO charts—are used. The MA chart assumes that the mean of the process should be stationary, and computes the mean of the prediction process residual as a two week rolling average. Using this method, an \ac{UCL} and \ac{LCL} are calculated to determine when a process is ``out of control" and is defined as:

\begin{equation}
    \text{UCL / LCL} = \mu +/- \frac{3\sigma}{\sqrt{n * w}}
\end{equation}

where $\sigma$ is the standard deviation of the process up to the time within window $w$, $n$ is the number of samples averaged at each time point, and $w$ is the total number of samples in the rolling window. Points lying outside of the UCL or LCL indicate the process is deviating from the expected behavior. The RO chart calculates the $99\%$ percentile of residuals in the preceding week, with a point being labeled ``hard to predict" if the residual lies in the $99\%$. Combining the RO and MA chart allows one to identify a change in mean of the MA chart and corresponding analysis into which point(s) caused the change indicated by the RO chart. This charting methodology flagged a problem with the HVAC system of the building, and upon inspection, the engineer identified excessive overnight cycling of the HVAC system—resulting in unnecessary energy consumption and equipment usage. 

Building off of the MLR model developed in the case study with the pharmaceutical manufacturing plant \cite{cas}, control charts were developed to identify the EE of the CAS over time. In this study, the authors used instantaneous and the \ac{CuSum} of residuals. Instantaneous and the CuSum of residuals is given by,
\begin{equation}
    \text{Instantaneous} = \Delta \text{E}(t) = \text{E}_{act}(t) - \text{E}_{pred}(t)
\end{equation}
\begin{equation}
    \text{CuSum} = \Delta \text{EC}(t) = \sum_{t=0}^t\Delta \text{E}(t)
\end{equation}

where $\text{E}_{act}(t)$ is the actual energy consumption of the system at time $t$ and $\text{E}_{pred}(t)$ is the predicted energy consumption at time $t$. The difference between these two is the residual, whereas the CuSum is the cumulative sum of residuals from $t=0$ to $t=n-1$. In addition, UCL and LCL were also defined similar to \cite{tightening} to determine the significance of the CAS deviations. However, in this case study, the control limits were defined by $2 \sigma * \Delta \text{E}(t)$. 

Using these two control charts, the authors identified three different operating conditions over a time period of one year. The charts were then reviewed by the operators of the CAS where the first two were related to a maintenance and process intervention; respectively. Lastly, the third operating condition represented an evident malfunctioning of a compressor that remained stuck in stand-by for three consecutive days.

The control charts utilized by \cite{boiler} were developed off of the \ac{EWMA} statistic which gives less weight to older observations and provides an indication of the direction of the boilers performance and the symptoms of possible malfunctions and is defined by:

\begin{equation}
    y_t = y_{t-1} + \lambda e_t
\end{equation}

where $y_t$ is the EWMA at time $t$, $\lambda$ is a constant between $0$ and $1$ which determines the memory length, $e_t$ is the observed change $\hat{y_t} - y_{t-1}$ and $\hat{y_t}$ is the observed MA of the sample at time $t$. Subsequently, UCL and LCL were developed using the EWMA statistic to identity the significance in deviations of efficiency:

\begin{equation}
    T \pm \sqrt{(\frac{\lambda}{2 - \lambda})\sigma}
\end{equation}

where $T$ is the target value and represents the mean in the process history and $\sigma$ is the standard deviation in the process history. The baseline model, complemented with the EWMA control chart, identified a series of ``out of control" points that signaled the corner-fired boiler was operating below its expected efficiency. As a root cause analysis, the variables used in the MLR and time period leading up to and after the out of control points were analyzed. In conclusion, it was found that the independent variables were exhibiting more variance than in the baseline period used to train the model.