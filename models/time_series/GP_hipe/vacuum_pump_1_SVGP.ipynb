{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import sys\n",
    "sys.path.append('/Users/wastechs/Documents/git-repos/energy-efficiency')\n",
    "from lib.util.helper import query_table, weekday_time_series\n",
    "from validation.gp.create_train_inference import create_train_inference_gp\n",
    "from lib.util import helper, data_preprocessing\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import gpytorch\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import torch\n",
    "import tqdm\n",
    "import gpytorch\n",
    "from gpytorch.models import ApproximateGP\n",
    "from gpytorch.variational import CholeskyVariationalDistribution\n",
    "from gpytorch.variational import VariationalStrategy\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = query_table(table='vacuum_pump_1_30T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['kw'] = round(df['kw'], 2)\n",
    "df['kw'] = df['kw'].apply(lambda x: 0.0 if x == -0.0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1632, 3)\n"
     ]
    }
   ],
   "source": [
    "#df = df[df.index < '2017-12-09']\n",
    "df = df[(df.index >= '2017-11-05') & (df.index < '2017-12-09')]\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "time_int_range = np.arange(0, df.shape[0]*30, 30)\n",
    "df['t'] = time_int_range\n",
    "df['t'] = (df['t'] - df['t'].min()) / (df['t'].max() - df['t'].min())\n",
    "\n",
    "training = df[df.index < '2017-12-08']\n",
    "testing = df[df.index >= '2017-12-08']\n",
    "\n",
    "X_train = torch.from_numpy(training['t'].values).to(torch.double)\n",
    "y_train = torch.from_numpy(training['kw'].values).to(torch.double)\n",
    "\n",
    "X_test = torch.from_numpy(df['t'].values).to(torch.float32)\n",
    "X_test_sub = torch.from_numpy(testing['t'].values).to(torch.double)\n",
    "y_test = torch.from_numpy(testing['kw'].values).to(torch.double)\n",
    "\n",
    "# Standardizing helps with hyperparameter initialization\n",
    "y_train_mean = torch.mean(y_train)\n",
    "y_train_std = torch.std(y_train)\n",
    "\n",
    "y_train = (y_train - y_train_mean) / (y_train_std)\n",
    "y_test = (y_test - y_train_mean) / (y_train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_sub, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float64, torch.float32, torch.float64, torch.float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtype, X_test.dtype, y_train.dtype, y_test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## v1 - end loss = 1.09 ##\n",
    "\n",
    "class GPModel(ApproximateGP):\n",
    "    def __init__(self, inducing_points):\n",
    "\n",
    "        variational_distribution = CholeskyVariationalDistribution(inducing_points.size(0))\n",
    "        variational_strategy = VariationalStrategy(\n",
    "            self, inducing_points, variational_distribution, learn_inducing_locations=True)\n",
    "\n",
    "        super(GPModel, self).__init__(variational_strategy)\n",
    "\n",
    "        period_constraint_short = gpytorch.constraints.Interval(0.034, 0.045) ## short term 1\n",
    "\n",
    "        seasonal_periodic_short = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.PeriodicKernel(\n",
    "                period_length_constraint=period_constraint_short\n",
    "                )\n",
    "            )\n",
    "\n",
    "\n",
    "        ## Local Variations ##\n",
    "        local_variation_alpha = gpytorch.priors.GammaPrior(1, 0.5)\n",
    "\n",
    "        local_variation = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.RQKernel()\n",
    "            )\n",
    "            \n",
    "        local_variation.alpha = 1\n",
    "\n",
    "        self.covar_module = seasonal_periodic_short + local_variation\n",
    "        self.mean_module = gpytorch.means.ZeroMean()\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# initialize likelihood and model\n",
    "inducing_points = X_train[:500]\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = GPModel(inducing_points=inducing_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dcab2337c294b89b41da89bfe0a6231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca373370c874a08a7fa488613a66a66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c331c8fc2b9f420692173e69619211a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caad6a42f39c466abadc526553d538db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "731269c370a549c48a9af60ba0410383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Minibatch:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "smoke_test = ('CI' in os.environ)\n",
    "num_epochs = 1 if smoke_test else 4\n",
    "\n",
    "model.double()\n",
    "likelihood.double()\n",
    "\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.parameters()},\n",
    "    {'params': likelihood.parameters()},\n",
    "], lr=0.01)\n",
    "\n",
    "\n",
    "mll = gpytorch.mlls.VariationalELBO(likelihood, model, num_data=y_train.size(0))\n",
    "\n",
    "epochs_iter = tqdm.notebook.tqdm(range(num_epochs), desc=\"Epoch\")\n",
    "for i in epochs_iter:\n",
    "    # Within each iteration, we will go over each minibatch of data\n",
    "    minibatch_iter = tqdm.notebook.tqdm(train_loader, desc=\"Minibatch\", leave=False)\n",
    "    for x_batch, y_batch in minibatch_iter:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x_batch)\n",
    "        loss = -mll(output, y_batch)\n",
    "        minibatch_iter.set_postfix(loss=loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in test_loader:\n",
    "        preds = model(x_batch)\n",
    "        #means = torch.cat([means, preds.mean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0007, -0.0013, -0.0022, -0.0035, -0.0050, -0.0068, -0.0086, -0.0105,\n",
       "        -0.0122, -0.0136, -0.0144, -0.0143, -0.0133, -0.0112, -0.0079, -0.0036],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "55f578ea790fce859303417df5f33993e9db329ffe5a387d7c54812db965934b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('thesis': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
