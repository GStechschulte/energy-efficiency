{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5b31229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import torch\n",
    "import gpytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9ef136",
   "metadata": {},
   "source": [
    "### Seasonality\n",
    "\n",
    "Data is collected at 5 minute intervals over a 10 day timespan\n",
    "\n",
    "Frequency = Number of observations per _season_ or _cycle_\n",
    "\n",
    "Season = Hour, Day, Week, Month, Quarter, Year\n",
    "\n",
    "_Note_: In Fourier analysis, “period” is the length of the cycle, and “frequency” is the inverse of period\n",
    "\n",
    "Daily seasonality frequency of $288 = (24 * 60) / 5$\n",
    "\n",
    "Day of week seasonality frequency of $2016 = (288 * 7)$\n",
    "\n",
    "Work Week seasonality frequency of $1440 = (288 * 5)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d40625d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sigma_line = query_table(table='uv_sigma_line_eg_5T')\n",
    "sigma_line = pd.read_csv('/Users/wastechs/Downloads/machine_day12.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7e20ff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_line.set_index(sigma_line.t, inplace=True)\n",
    "del sigma_line['t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5f82b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(data_frame=sigma_line, x=sigma_line.index, y='p')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd6190b",
   "metadata": {},
   "source": [
    "### Scale $X$ between [0-1] and use double precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "cc3958ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1728, 9)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_line.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "58e1ea86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sigma_line = sigma_line[sigma_line.index.day >= 12] ## for pedagoical reasons\n",
    "\n",
    "time_int_range = np.arange(0, 1728*5, 5)\n",
    "sigma_line['t'] = time_int_range\n",
    "\n",
    "X = (sigma_line['t'].values - np.min(sigma_line['t'].values)) / (np.max(sigma_line['t'].values) - np.min(sigma_line['t'].values))\n",
    "y = sigma_line['kw'].values\n",
    "\n",
    "n = len(X)\n",
    "\n",
    "prop_train = 0.7\n",
    "n_train = round(prop_train * n)\n",
    "\n",
    "X_train = torch.from_numpy(X[:n_train]).to(torch.double)\n",
    "y_train = torch.from_numpy(y[:n_train]).to(torch.double)\n",
    "\n",
    "y_train_mean = torch.mean(y_train)\n",
    "y_train_std = torch.std(y_train)\n",
    "\n",
    "X_test = torch.from_numpy(X[n_train:]).to(torch.double)\n",
    "y_test = torch.from_numpy(y[n_train:]).to(torch.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c419cc36",
   "metadata": {},
   "source": [
    "### Keep $X$ the same and use float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6e557987",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_int_range = np.arange(0, 1728*5, 5)\n",
    "all['t'] = time_int_range\n",
    "\n",
    "X = all['t'].values\n",
    "y = all['kw'].values\n",
    "\n",
    "n = len(X)\n",
    "\n",
    "prop_train = 0.7\n",
    "n_train = round(prop_train * n)\n",
    "\n",
    "X_train = torch.from_numpy(X[:n_train]).to(torch.float32)\n",
    "y_train = torch.from_numpy(y[:n_train]).to(torch.float32)\n",
    "\n",
    "y_train_mean = torch.mean(y_train)\n",
    "y_train_std = torch.std(y_train)\n",
    "\n",
    "X_test = torch.from_numpy(X[n_train:]).to(torch.float32)\n",
    "y_test = torch.from_numpy(y[n_train:]).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9922e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        period_prior = gpytorch.priors.NormalPrior(30, 1.5)\n",
    "        period_constraint = gpytorch.constraints.Interval(10, 60)\n",
    "        outputscale_prior = gpytorch.priors.GammaPrior(0.5, 0.15)\n",
    "        \n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.PeriodicKernel(\n",
    "                period_length_prior=period_prior,\n",
    "                period_length_constraint=period_constraint\n",
    "                ) * gpytorch.kernels.RBFKernel(),\n",
    "                outputscale_prior=outputscale_prior\n",
    "            )\n",
    "\n",
    "        # Initialize lengthscale and output scale to mean of priors\n",
    "        #self.covar_module.outputscale = outputscale_prior.mean\n",
    "        #self.covar_module.base_kernel.lengthscale = lengthscale_prior\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# initialize likelihood and model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(X_train, y_train, likelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40baf07b",
   "metadata": {},
   "source": [
    "Actual learned parameters of the model are things like raw_noise, raw_outputscale, raw_lengthscale, etc. The reason for this is that these parameters must be positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a57dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Actual outputscale:', model.covar_module.outputscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf3c24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252589ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.double()\n",
    "likelihood.double()\n",
    "\n",
    "model.train()\n",
    "likelihood.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b219c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gpytorch.settings.max_cg_iterations(5000):\n",
    "    # Use the adam optimizer\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {'params': model.parameters()},  # Includes Gaussian Likelihood parameters\n",
    "        ], lr=0.01)\n",
    "\n",
    "    # \"Loss\" for GPs - the marginal log likelihood\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    training_iter = 300\n",
    "    for i in range(training_iter):\n",
    "        # Zero gradients from previous iteration\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Output from model\n",
    "        output = model(X_train)\n",
    "\n",
    "        # Calc loss and backprop gradients\n",
    "        loss = -mll(output, y_train)\n",
    "        loss.backward()\n",
    "\n",
    "        if (i % 20) == 0:\n",
    "            print('Iter %d/%d - Loss: %.3f noise: %.6f' % (\n",
    "                i + 1, training_iter, loss.item(),\n",
    "                model.likelihood.noise.item()\n",
    "            ))\n",
    "            print(list(model.parameters()))\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d523cdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_outputscale = model.covar_module.raw_outputscale\n",
    "constraint = model.covar_module.raw_outputscale_constraint\n",
    "\n",
    "print('Transformed outputscale: ', constraint.transform(raw_outputscale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480f2060",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Actual outputscale:', model.covar_module.outputscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f40622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get into evaluation (predictive posterior) mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Make predictions by feeding model through likelihood\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var(), gpytorch.settings.max_cg_iterations(9000):\n",
    "    #test_x = test_x.to(torch.float32)\n",
    "    test_pred = likelihood(model(X_test))\n",
    "    train_pred = likelihood(model(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd16c951",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    # Initialize plot\n",
    "    f, ax = plt.subplots(1, 1, figsize=(20, 6))\n",
    "    # Get upper and lower confidence bounds\n",
    "    #lower, upper = observed_pred.confidence_region()\n",
    "    # Plot training data as black stars\n",
    "    ax.plot(X_train.numpy(), y_train.numpy(), alpha=0.7)\n",
    "    ax.plot(X_train.numpy(), train_pred.mean.numpy())\n",
    "    # Plot predictive means as blue line\n",
    "    ax.plot(X_test.numpy(), y_test.numpy())\n",
    "    ax.plot(X_test.numpy(), test_pred.mean.numpy(), lw=4)\n",
    "    # Shade between the lower and upper confidence bounds\n",
    "    #ax.fill_between(X_test.numpy(), lower.numpy(), upper.numpy(), alpha=0.5, color='#2ecc71')\n",
    "    ax.legend(['Observed Data', 'Training', 'Test', 'Predictions'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
